# pyspark-Assignment

ðŸ”´ **Assignment - 1** consists of the queries and operation related to RDD concept in PySpark. The analysis.txt file contains the respective results and observations.  
ðŸ”´ **Assignment - 2** consists of the queries and operations related to DataFrames in PySpark   
  
Setting up Environment variables for pyspark operations -   
During my practise and operations Py4JJavaError which riss due to the incorrect settings of ENV variable in windows system  

## The follwing environment variables are to be set accordingly -  
ðŸ”´ **HADOOP_HOME** : The path to spark - hadoop directory **...\spark-(version)-bin-hadoop3**  
ðŸ”´ **SPARK_HOME**  : The path to spark - hadoop directory **...\spark-(version)-bin-hadoop3**  
ðŸ”´ **PYTHONPATH**  : The path to Py4j zip folder inside spark-hadoop folder **...\python\lib\py4j-(version)-src.zip**  
ðŸ”´ **PYSPARK_PYTHON**  : The path to python.exe file should be provided here **...\Python39\python.exe**  
ðŸ”´ **PYSPARK_DRIVER_PYTHON**  : The path to python.exe file should be provided here **...\Python39\python.exe**  

## Also pip install pyspark which also installs py4j packages  
## Install Java-JDK which is necessary to run and execute spark 
